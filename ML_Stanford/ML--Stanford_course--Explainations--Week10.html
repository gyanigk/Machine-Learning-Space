<!doctype html><html>
    <head>
      <meta http-equiv="content-type" content="text/html; charset=utf-8">
      <title>Week10</title>
      <meta name="generator" content="CherryTree">
      <link rel="stylesheet" href="res/styles3.css" type="text/css" />
    </head>
    <body><div class='page'><h1 class='title'>Week10</h1><br/>Learning With large datasets<br /><a href=""><img src="images/24-1.png" alt="images/24-1.png" /></a><br /><br /><a href=""><img src="images/24-2.png" alt="images/24-2.png" /></a><br /><br />Stochastic Gradient Descent<br /><a href=""><img src="images/24-3.png" alt="images/24-3.png" /></a><br /> what Stochastic gradient descent is doing is it is actually scanning through the training examples. And first it&#39;s gonna look at my first training example x(1), y(1). <br />And then looking at only this first example, it&#39;s gonna take like a basically a little gradient descent step with respect to the cost of just this first training example. So in other words, we&#39;re going to look at the first example and modify the parameters a little bit to fit just the first training example a little bit better. <br />Having done this inside this inner for-loop is then going to go on to the second training example. And what it&#39;s going to do there is take another little step in parameter space, so modify the parameters just a little bit to try to fit just a second training example a little bit better. <br />Having done that, is then going to go onto my third training example. <br />And modify the parameters to try to fit just the third training example a little bit better, and so on until you know, you get through the entire training set. And then this ultra repeat loop may cause it to take multiple passes over the entire training set. This view of Stochastic gradient descent also motivates why we wanted to start by randomly shuffling the data set. <br />This doesn&#39;t show us that when we scan through the training site here, that we end up visiting the training examples in some sort of randomly sorted order. Depending on whether your data already came randomly sorted or whether it came originally sorted in some strange order, in practice this would just speed up the conversions to Stochastic gradient descent just a little bit. <br />So in the interest of safety, it&#39;s usually better to randomly shuffle the data set if you aren&#39;t sure if it came to you in randomly sorted order. But more importantly another view of Stochastic gradient descent is that it&#39;s a lot like descent but rather than wait to sum up these gradient terms over all m training examples, what we&#39;re doing is we&#39;re taking this gradient term using just one single training example and we&#39;re starting to make progress in improving the parameters already. <br />So rather than, you know, waiting &#39;till taking a path through all 300,000 United States Census records, say, rather than needing to scan through all of the training examples before we can modify the parameters a little bit and make progress towards a global minimum. For Stochastic gradient descent instead we just need to look at a single training example and we&#39;re already starting to make progress in this case of parameters towards, moving theparameters towards the global minimum. <br />So, here&#39;s the algorithm written out again where the first step is to randomly shuffle the data and the second step is where the real work is done, where that&#39;s the update with respect to asingle training example x(i), y(i). <br />So, let&#39;s see what this algorithm does to the parameters.<br /><a href=""><img src="images/24-4.png" alt="images/24-4.png" /></a><br /><br /><a href=""><img src="images/24-5.png" alt="images/24-5.png" /></a><br /><br /><br />Mini-Batch Gradient Descent<br /><a href=""><img src="images/24-6.png" alt="images/24-6.png" /></a><br /><br /> <br />One disadvantage of Mini-batch gradient descent is that there is now this extra parameter b, the Mini-batch size which you may have to fiddle with, and which may therefore take time. But if you have a good vectorized implementation this can sometimes run even faster that Stochastic gradient descent. <br />So that was Mini-batch gradient descent which is an algorithm that in some sense does something that&#39;s somewhat in between what Stochastic gradient descent does and what Batch gradient descent does. <br />And if you choose their reasonable value of b. I usually use b equals 10, but, you know, other values, anywhere from say 2 to 100, would be reasonably common. So we choose value of b and if you use a good vectorized implementation, sometimes it can be faster than both Stochastic gradient descent and faster than Batch gradient descent.<br /><br /><a href=""><img src="images/24-7.png" alt="images/24-7.png" /></a><br /><br /><br />Stochastic Gradient Descent convergence<br /><a href=""><img src="images/24-8.png" alt="images/24-8.png" /></a><br /><br />You don&#39;t want to have to pause stochastic gradient descent periodically in order to compute this cost function since it requires a sum of your entire training set size. <br />And the whole point of stochastic gradient was that you wanted to start to make progress after looking at just a single example without needing to occasionally scan through your entire training set right in the middle of the algorithm, just to compute things like the cost function of the entire training set. So for stochastic gradient descent, in order to check the algorithm is converging, here&#39;s what we can do instead. <br />Let&#39;s take the definition of the cost that we had previously. So the cost of the parameters theta with respect to a single training example is just one half of the square error on that training example. Then, while stochastic gradient descent is learning, right before we train on a specific example. <br />So, in stochastic gradient descent we&#39;re going to look at the examples xi, yi, in order, and then sort of take a little update with respect to this example. And we go on to the next example, xi plus 1, yi plus 1, and so on, right? That&#39;s what stochastic gradient descent does. So, while the algorithm is looking at the example xi, yi, but before it has updated the parameters theta using that an example, let&#39;s compute the cost of that example. And we want to do this before updating theta because if we&#39;ve just updated theta using example, you know, that it might be doing better on that example than what would be representative. <br />Finally, in order to check for the convergence of stochastic gradient descent, what we can do is every, say, every thousand iterations, we can plot these costs that we&#39;ve been computing in the previous step. <br />We can plot those costs average over, say, the last thousand examples processed by the algorithm. And if you do this, it kind of gives you a running estimate of how well the algorithm is doing. on, you know, the last 1000 training examples that your algorithm has seen. <br /><br /><a href=""><img src="images/24-9.png" alt="images/24-9.png" /></a><br /><br /> <br />One of the reasons people tend not to do this is because you end up needing to spend time playing with these 2 extra parameters, constant 1 and constant 2, and so this makes the algorithm more finicky. You know, it&#39;s just more parameters able to fiddle with in order to make the algorithm work well. <br />But if you manage to tune the parameters well, then the picture you can get is that the algorithm will actually around towards the minimum, but as it gets closer because you&#39;re decreasing the learning rate the meanderings will get smaller and smaller until it pretty much just to the global minimum. <br /><br /><a href=""><img src="images/24-10.png" alt="images/24-10.png" /></a><br /><a href=""><img src="images/24-11.png" alt="images/24-11.png" /></a><br /><br /><br />Online learning<br />The online learning setting allows us to model problems where we have a continuous flood or a continuous stream of data coming in and we would like an algorithm to learn from that. Today, many of the largest websites, or many of the largest website companies use different versions of online learning algorithms to learn from the flood of users that keep on coming to, back to the website. <br />Specifically, if you have a continuous stream of data generated by a continuous stream of users coming to your website, what you can do is sometimes use an online learning algorithm to learn user preferences from the stream of data and use that to optimize some of the decisions on your website.<br /><br /><a href=""><img src="images/24-12.png" alt="images/24-12.png" /></a><br /><br />learning the predicted click-through rate, the predicted CTR<br /><a href=""><img src="images/24-13.png" alt="images/24-13.png" /></a><br /><br /> that was the online learning setting and as we saw, the algorithm that we apply to it is really very similar to this schotastic gradient descent algorithm, only instead of scanning through a fixed training set, we&#39;re instead getting one example from a user, learning from that example, then discarding it and moving on. <br />And if you have a continuous stream of data for some application, this sort of algorithm may be <br />well worth considering for your application. <br />And of course, one advantage of online learning is also that if you have a changing pool of users, or if the things you&#39;re trying to predict are slowly changing like your user taste is slowly changing, the online learning algorithm can slowly adapt your learned hypothesis to whatever the latest sets of user behaviors are like as well.<br /><br /><br /><br />Map reduce and Data parallelism<br /><br />Jeffrey dean Sanjay ghemawat<br /><br /><a href=""><img src="images/24-14.png" alt="images/24-14.png" /></a><br /><br /><a href=""><img src="images/24-15.png" alt="images/24-15.png" /></a><br /><br /><a href=""><img src="images/24-16.png" alt="images/24-16.png" /></a><br /><br /><a href=""><img src="images/24-17.png" alt="images/24-17.png" /></a><br /><br /><br /><br /><br /><br /><br /> </div></body></html>