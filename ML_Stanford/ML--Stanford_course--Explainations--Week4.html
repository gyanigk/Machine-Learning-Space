<!doctype html><html>
    <head>
      <meta http-equiv="content-type" content="text/html; charset=utf-8">
      <title>Week4</title>
      <meta name="generator" content="CherryTree">
      <link rel="stylesheet" href="res/styles3.css" type="text/css" />
    </head>
    <body><div class='page'><h1 class='title'>Week4</h1><br/>Neural Networks<br /><br />Nonlinear Hypotheses<br /><br />Learning algorithm<br />Supervised learning - logistic regression<br /><a href=""><img src="images/18-1.png" alt="images/18-1.png" /></a><br />non-linear classification <br /><a href=""><img src="images/18-2.png" alt="images/18-2.png" /></a><br /><a href=""><img src="images/18-3.png" alt="images/18-3.png" /></a><br /><a href=""><img src="images/18-4.png" alt="images/18-4.png" /></a><br /><br />it is too large to solve fast<br /><br /><br />Neurons and brain<br />computationally expensive algorithms<br /><br /><a href=""><img src="images/18-5.png" alt="images/18-5.png" /></a><br /><a href=""><img src="images/18-6.png" alt="images/18-6.png" /></a><br /><a href=""><img src="images/18-7.png" alt="images/18-7.png" /></a><br /><a href=""><img src="images/18-8.png" alt="images/18-8.png" /></a><br /><br /><br />Neural Networks<br />Model representation I<br /><br />represent hypotheses  or model<br /><br />neuron model : logistic unit<br />X0 is bias unit. outputs the value 1<br />weights: paramenters<br /><a href=""><img src="images/18-9.png" alt="images/18-9.png" /></a><br /><a href=""><img src="images/18-10.png" alt="images/18-10.png" /></a><br /><a href=""><img src="images/18-11.png" alt="images/18-11.png" /></a><br /><h3> </h3>At a very simple level, neurons are basically computational units that take inputs (dendrites) as electrical inputs (called &quot;spikes&quot;) that are channeled to outputs (axons). In our model, our dendrites are like the input features x_1\cdots x_nx1​⋯xn​, and the output is the result of our hypothesis function. In this model our x_0x0​ input node is sometimes called the &quot;bias unit.&quot; It is always equal to 1. In neural networks, we use the same logistic function as in classification, \frac{1}{1 + e^{-\theta^Tx}}1+e−θTx1​, yet we sometimes call it a sigmoid (logistic) activation function. In this situation, our &quot;theta&quot; parameters are sometimes called &quot;weights&quot;.<br /><br /><br />Model representation II<br /><br />forward propagation : vectorized implementation<br />linear combination that go into a particular neuron<br /><a href=""><img src="images/18-12.png" alt="images/18-12.png" /></a><br /><br />neural networks learning its own features<br /><a href=""><img src="images/18-13.png" alt="images/18-13.png" /></a><br />other network architectures<br /><a href=""><img src="images/18-14.png" alt="images/18-14.png" /></a><br /><h3>In this section we&#39;ll do a vectorized implementation of the above functions. We&#39;re going to define a new variable z_k^{(j)}</h3><em><h3>z</h3></em><em><h3>k</h3></em><h3>(</h3><em><h3>j</h3></em><h3>)</h3><small>​</small><h3> that encompasses the parameters inside our g function.</h3><br /><a href=""><img src="images/18-15.png" alt="images/18-15.png" /></a><a href=""><img src="images/18-16.png" alt="images/18-16.png" /></a><a href=""><img src="images/18-17.png" alt="images/18-17.png" /></a><a href=""><img src="images/18-18.png" alt="images/18-18.png" /></a><br /><a href=""><img src="images/18-19.png" alt="images/18-19.png" /></a><br /><br /><br />Applications<br /><br />Examples And intuition I<br />non-linear decision boundary<br /><a href=""><img src="images/18-20.png" alt="images/18-20.png" /></a><br /><br /><a href=""><img src="images/18-21.png" alt="images/18-21.png" /></a><br /><a href=""><img src="images/18-22.png" alt="images/18-22.png" /></a><br /><br /><a href=""><img src="images/18-23.png" alt="images/18-23.png" /></a><br /><a href=""><img src="images/18-24.png" alt="images/18-24.png" /></a><br /> <br />multiclass classification<br /><a href=""><img src="images/18-25.png" alt="images/18-25.png" /></a><br /><a href=""><img src="images/18-26.png" alt="images/18-26.png" /></a><br /><br /><br /><br /> </div></body></html>