{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1627726522924
    },
    "id": "LyLJk3IV7e39",
    "outputId": "eb6b0837-7c6c-45a7-9241-6533b16bc8ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping keras as it is not installed.\n",
      "WARNING: Skipping keras-nightly as it is not installed.\n",
      "WARNING: Skipping keras-Preprocessing as it is not installed.\n",
      "WARNING: Skipping keras-vis as it is not installed.\n",
      "WARNING: Skipping tensorflow as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras -y\n",
    "!pip uninstall keras-nightly -y\n",
    "!pip uninstall keras-Preprocessing -y\n",
    "!pip uninstall keras-vis -y\n",
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow\n",
    "!pip install keras \n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627751705869
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 17:15:07.121637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam#Try all of these\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1627744689030
    },
    "id": "MfQJxQLb76jp",
    "outputId": "bb45954f-0ee7-44be-b639-c25dea1cf187"
   },
   "outputs": [],
   "source": [
    "#!wget \"https://s3-ap-southeast-1.amazonaws.com/he-public-data/dataset52a7b21.zip\"\n",
    "#!unzip dataset52a7b21.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627744762097
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2903024"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_df)=2903024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1627744869799
    },
    "id": "64S_1Iyw-FQu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv('dataset/train.csv',escapechar = \"\\\\\",quoting = csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gather": {
     "logged": 1627744870166
    },
    "id": "GpGbsCIc8SgA"
   },
   "outputs": [],
   "source": [
    "x = train_df['TITLE'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627744870743
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 15:21:12.494732: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-31 15:21:12.495353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0001:00:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-31 15:21:12.495409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-31 15:21:12.495445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-31 15:21:12.495466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-31 15:21:12.495485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-31 15:21:12.495532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-31 15:21:12.495557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-31 15:21:12.495576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-31 15:21:12.495595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-31 15:21:12.496306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-31 15:21:12.496346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-31 15:21:12.496354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-31 15:21:12.496360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-31 15:21:12.497153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 10624 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7)\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    " raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "gather": {
     "logged": 1627744973302
    },
    "id": "UzccOX546Mcs"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y=le.fit_transform(train_df['BROWSE_NODE_ID'])\n",
    "#y=np.expand_dims(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1627744975079
    },
    "id": "IUjbeiAq6MCz"
   },
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "gather": {
     "logged": 1627744978261
    },
    "id": "SWhnsWID-8LT"
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "max_text_length = 400 #find the text with max length in code and change it for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1627745015146
    },
    "id": "R7SYc_Mp_aDn",
    "outputId": "0b6ea1bc-c676-4448-c5cf-08238e932be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happened\n",
      "Happened\n"
     ]
    }
   ],
   "source": [
    "x_tokenizer =text.Tokenizer(max_features)\n",
    "x_tokenizer.fit_on_texts(list(x))\n",
    "print(\"Happened\")\n",
    "x_tokenized = x_tokenizer.texts_to_sequences(x)\n",
    "print(\"Happened\")\n",
    "x_train_val = sequence.pad_sequences(x_tokenized, maxlen=max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1627745015444
    },
    "id": "INYtPwh8_dE9",
    "outputId": "8f810085-a4cc-4c05-d503-d9d1b28ea119"
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1627745060650
    },
    "id": "zj08cHToVSA1",
    "outputId": "c55d4662-7765-4f60-ebce-dbb29b1a6326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "embedding_index = dict()\n",
    "f = open('glove.6B.300d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "gather": {
     "logged": 1627745060794
    },
    "id": "hLAOP9ozYIx1"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "for word, index in x_tokenizer.word_index.items():\n",
    "  if index>max_features -1:\n",
    "    break\n",
    "  else:\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      embedding_matrix[index] = embedding_vector\n",
    "del(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627748965518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix=np.float32(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627745061096
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dbfile = open('embeddingmatrix.pkl','ab')\n",
    "pickle.dump(embedding_matrix, dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627748968733
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "max_features = 20000\n",
    "max_text_length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627748979258
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,\n",
    "                                                  y,\n",
    "                                                  random_state=1,\n",
    "                                                  test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "gather": {
     "logged": 1627749024136
    },
    "id": "Hn-sjHYZDHLU"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dim,\n",
    "                    embeddings_initializer=tf.keras.initializers.Constant(\n",
    "                        embedding_matrix)))#,trainable=False\n",
    "model.add(Dropout(0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627749027855
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9150"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_classes=len(train_df.BROWSE_NODE_ID.unique())\n",
    "no_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1627749029230
    },
    "id": "FLEToGmCb3ZF",
    "outputId": "5bf8855b-0d4d-4841-bc0e-92c51f6ada6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 300)         6000000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, None, 500)         450500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12000)             6012000   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12000)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 9150)              109809150 \n",
      "=================================================================\n",
      "Total params: 122,271,650\n",
      "Trainable params: 122,271,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv1D(500,\n",
    "                 3,\n",
    "                 padding='valid'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(12000, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(no_of_classes,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "gather": {
     "logged": 1627749084277
    },
    "id": "R9H3ExHlzXFR"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya9rhe8QcVrV"
   },
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627749086300
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627733851591
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627743879570
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits (logits-model, labels-y)) \n",
    "#optimizer = tf.train. AdamOptimizer (learning_rate learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "gather": {
     "logged": 1627750813079
    },
    "id": "i1lpjeBMepE-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 640/5997 [==>...........................] - ETA: 22:06 - loss: 5.8218 - accuracy: 0.2479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "1280/5997 [=====>........................] - ETA: 20:34 - loss: 4.9329 - accuracy: 0.3276\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "1920/5997 [========>.....................] - ETA: 18:00 - loss: 4.5129 - accuracy: 0.3681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "2560/5997 [===========>..................] - ETA: 15:16 - loss: 4.2530 - accuracy: 0.3941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "3200/5997 [===============>..............] - ETA: 12:28 - loss: 4.0716 - accuracy: 0.4125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "3840/5997 [==================>...........] - ETA: 9:39 - loss: 3.9356 - accuracy: 0.4264\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "4480/5997 [=====================>........] - ETA: 6:49 - loss: 3.8283 - accuracy: 0.4374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "5120/5997 [========================>.....] - ETA: 3:56 - loss: 3.7409 - accuracy: 0.4465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "5760/5997 [===========================>..] - ETA: 1:03 - loss: 3.6679 - accuracy: 0.4540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "5997/5997 [==============================] - 1701s 283ms/step - loss: 3.6436 - accuracy: 0.4564 - val_loss: 15.2921 - val_accuracy: 0.0719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 1\n",
    "\n",
    "#callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq=5*batch_size)\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "hist_adam=model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_val,y_val),\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.plot(hist_adam.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(hist_adam.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Run all the cells above before you sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Run all the cells below after the training is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627751835811
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 17:15:31.848560: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-31 17:15:31.849641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-31 17:15:31.905310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0001:00:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-31 17:15:31.905364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-31 17:15:31.908555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-31 17:15:31.908613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-31 17:15:31.910363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-31 17:15:31.910655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-31 17:15:31.912714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-31 17:15:31.913742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-31 17:15:31.913941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-31 17:15:31.915342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-31 17:15:31.915766: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-31 17:15:31.916060: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-31 17:15:31.916812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0001:00:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-31 17:15:31.916844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-31 17:15:31.916888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-31 17:15:31.916914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-31 17:15:31.916940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-31 17:15:31.916965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-31 17:15:31.916991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-31 17:15:31.917017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-31 17:15:31.917044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-31 17:15:31.918498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-31 17:15:31.918556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-31 17:15:32.470685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-31 17:15:32.470720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-31 17:15:32.470730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-31 17:15:32.473074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10624 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 300)         6000000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 500)         450500    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, None, 500)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 250)         625250    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, None, 250)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, None, 100)         175100    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12000)             1212000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 12000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 9150)              109809150 \n",
      "=================================================================\n",
      "Total params: 118,272,000\n",
      "Trainable params: 118,272,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627751839442
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('dataset/test.csv',escapechar = \"\\\\\",quoting = csv.QUOTE_NONE)\n",
    "x = test_df['TITLE'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627751930777
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happened\n",
      "Happened\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "max_text_length = 400\n",
    "x_tokenizer =text.Tokenizer(max_features)\n",
    "x_tokenizer.fit_on_texts(list(x))\n",
    "print(\"Happened\")\n",
    "x_tokenized = x_tokenizer.texts_to_sequences(x)\n",
    "print(\"Happened\")\n",
    "x_test_val = sequence.pad_sequences(x_tokenized, maxlen=max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627751942705
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 5.4000e+01, 1.7000e+01,\n",
       "        1.8072e+04],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 6.0000e+00, 3.0000e+01,\n",
       "        2.7300e+02],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.4100e+02, 5.6000e+01,\n",
       "        2.7450e+03],\n",
       "       ...,\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.7000e+01, 1.0000e+01,\n",
       "        8.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.0000e+01, 3.4800e+02,\n",
       "        1.8400e+02],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.7000e+01, 1.0000e+01,\n",
       "        1.4000e+01]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_val=np.float32(x_test_val)\n",
    "x_test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627752073781
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 17:19:32.725537: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-31 17:19:32.726066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2596985000 Hz\n",
      "2021-07-31 17:19:32.846084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-31 17:19:33.039336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-31 17:19:33.051071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-31 17:19:33.997781: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-07-31 17:19:34.070991: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-07-31 17:21:13.213920: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4054365000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "pred1=new_model.predict(x_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627752726889
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sub=pd.read_csv('dataset/sample_submission.csv',escapechar = \"\\\\\",quoting = csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627753771337
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "len(pred1[3])\n",
    "train_df=pd.read_csv('dataset/train.csv',escapechar = \"\\\\\",quoting = csv.QUOTE_NONE)\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(train_df['BROWSE_NODE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627753772237
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627754186367
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pred=[]\n",
    "for item in range(len(pred1)):\n",
    "    ind = np.argpartition(pred1[item], -5)[-5:]\n",
    "    pred.append([ind[np.argsort(pred1[1,ind])][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627753316171
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ind = np.argpartition(pred1[1,:], -5)[-5:]\n",
    "#ind[np.argsort(pred1[1,ind])][-1] #, pred1[1,:]\n",
    "#pred1[1,ind]#np.max(pred1[1,ind])\n",
    "#np.argmax(pred1[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627754299081
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 107,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 641,\n",
       " 4,\n",
       " 4,\n",
       " 2905,\n",
       " 1043,\n",
       " 4,\n",
       " 905,\n",
       " 890,\n",
       " 299,\n",
       " 4,\n",
       " 299,\n",
       " 4,\n",
       " 855,\n",
       " 65,\n",
       " 4,\n",
       " 4,\n",
       " 413,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 944,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 335,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1075,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 903,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 369,\n",
       " 63,\n",
       " 279,\n",
       " 4,\n",
       " 4,\n",
       " 935,\n",
       " 944,\n",
       " 4,\n",
       " 1200,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 494,\n",
       " 4,\n",
       " 683,\n",
       " 145,\n",
       " 64,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 47,\n",
       " 754,\n",
       " 4,\n",
       " 903,\n",
       " 903,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 911,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 63,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1075,\n",
       " 4,\n",
       " 335,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 660,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 963,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 808,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1778,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 36,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 294,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1017,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 968,\n",
       " 679,\n",
       " 1769,\n",
       " 1493,\n",
       " 855,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1699,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 329,\n",
       " 4,\n",
       " 1479,\n",
       " 2417,\n",
       " 1696,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 667,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 683,\n",
       " 808,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 531,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 161,\n",
       " 944,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 1261,\n",
       " 4,\n",
       " 156,\n",
       " 4,\n",
       " 4,\n",
       " 1075,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 683,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 718,\n",
       " 4,\n",
       " 4,\n",
       " 3706,\n",
       " 5412,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1231,\n",
       " 4,\n",
       " 683,\n",
       " 683,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 649,\n",
       " 1019,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1769,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 60,\n",
       " 101,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3279,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1023,\n",
       " 956,\n",
       " 4,\n",
       " 4,\n",
       " 1869,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 956,\n",
       " 855,\n",
       " 4,\n",
       " 4,\n",
       " 440,\n",
       " 1010,\n",
       " 4,\n",
       " 2239,\n",
       " 4,\n",
       " 743,\n",
       " 3150,\n",
       " 131,\n",
       " 4,\n",
       " 2208,\n",
       " 427,\n",
       " 1608,\n",
       " 4,\n",
       " 656,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 683,\n",
       " 63,\n",
       " 4,\n",
       " 808,\n",
       " 372,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 4,\n",
       " 800,\n",
       " 1687,\n",
       " 2169,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 554,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 194,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2323,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 1023,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 694,\n",
       " 4,\n",
       " 194,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 161,\n",
       " 47,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 388,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 813,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 22,\n",
       " 1988,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 63,\n",
       " 4,\n",
       " 4,\n",
       " 1407,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 891,\n",
       " 4,\n",
       " 4,\n",
       " 800,\n",
       " 1023,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 808,\n",
       " 107,\n",
       " 1339,\n",
       " 4,\n",
       " 1699,\n",
       " 1060,\n",
       " 4,\n",
       " 903,\n",
       " 4,\n",
       " 4,\n",
       " 691,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 101,\n",
       " 4,\n",
       " 4,\n",
       " 2323,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 649,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 335,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 903,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1540,\n",
       " 903,\n",
       " 4,\n",
       " 1023,\n",
       " 4,\n",
       " 60,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 294,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 944,\n",
       " 4,\n",
       " 808,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 396,\n",
       " 4,\n",
       " 1075,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 784,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 677,\n",
       " 683,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 4,\n",
       " 808,\n",
       " 4,\n",
       " 743,\n",
       " 743,\n",
       " 743,\n",
       " 1613,\n",
       " 743,\n",
       " 956,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 1367,\n",
       " 903,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 591,\n",
       " 4,\n",
       " 683,\n",
       " 4,\n",
       " 4,\n",
       " 678,\n",
       " 1200,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1023,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 668,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 95,\n",
       " 4,\n",
       " 800,\n",
       " 4,\n",
       " 2554,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 590,\n",
       " 4,\n",
       " 4,\n",
       " 948,\n",
       " 4,\n",
       " 3202,\n",
       " 335,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 878,\n",
       " 4,\n",
       " 1987,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1415,\n",
       " 4,\n",
       " 4,\n",
       " 1380,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 335,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 530,\n",
       " 4,\n",
       " 4,\n",
       " 678,\n",
       " 4,\n",
       " 1494,\n",
       " 4,\n",
       " 891,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 908,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 808,\n",
       " 4,\n",
       " 4,\n",
       " 956,\n",
       " 161,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 299,\n",
       " 1432,\n",
       " 4,\n",
       " 4,\n",
       " 1075,\n",
       " 683,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 95,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 649,\n",
       " 4,\n",
       " 683,\n",
       " 3890,\n",
       " 226,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 942,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 903,\n",
       " 4,\n",
       " 4,\n",
       " 427,\n",
       " 4,\n",
       " 4,\n",
       " 439,\n",
       " 4,\n",
       " 194,\n",
       " 4,\n",
       " 4,\n",
       " 688,\n",
       " 4,\n",
       " 656,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 471,\n",
       " 4,\n",
       " 1231,\n",
       " 656,\n",
       " 4,\n",
       " 4,\n",
       " 2391,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 104,\n",
       " 1341,\n",
       " 4,\n",
       " 185,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2579,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 731,\n",
       " 4,\n",
       " 855,\n",
       " 743,\n",
       " 4,\n",
       " 4,\n",
       " 691,\n",
       " 743,\n",
       " 808,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1148,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 677,\n",
       " 4,\n",
       " 335,\n",
       " 1700,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 194,\n",
       " 1403,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 60,\n",
       " 530,\n",
       " 427,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1101,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2323,\n",
       " 133,\n",
       " 656,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1060,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 194,\n",
       " 2550,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 95,\n",
       " 1534,\n",
       " 4,\n",
       " 4,\n",
       " 2059,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4231,\n",
       " 677,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 165,\n",
       " 4,\n",
       " 295,\n",
       " 905,\n",
       " 4,\n",
       " 194,\n",
       " 4,\n",
       " 4,\n",
       " 2059,\n",
       " 4,\n",
       " 441,\n",
       " 4,\n",
       " 4,\n",
       " 591,\n",
       " 649,\n",
       " 4,\n",
       " 4,\n",
       " 878,\n",
       " 1476,\n",
       " 4,\n",
       " 4,\n",
       " 1161,\n",
       " 4,\n",
       " 4,\n",
       " 2323,\n",
       " 4,\n",
       " 4,\n",
       " 887,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2579,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 301,\n",
       " 4,\n",
       " 4,\n",
       " 63,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 743,\n",
       " 299,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [item for sublist in pred for item in sublist]\n",
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627754307284
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "y=le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627754673212
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRODUCT_ID', 'BROWSE_NODE_ID'], dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627754765807
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903024, 110775)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627754920358
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>BROWSE_NODE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  BROWSE_NODE_ID\n",
       "0           1               4\n",
       "1           2             122\n",
       "2           3               4\n",
       "3           4               4\n",
       "4           5               4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'PRODUCT_ID': test_df.PRODUCT_ID, 'BROWSE_NODE_ID': y}\n",
    "SUBMISSION = pd.DataFrame(data=d)\n",
    "SUBMISSION.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1627755090140
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "SUBMISSION.to_csv('First_Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "sequence_length = train_df.shape[1]\n",
    "filter_sizes = [3,4]\n",
    "num_filters = 100\n",
    "drop = 0.4\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=(1,1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(1,1))(conv_1)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((2*num_filters,))(flatten)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "conc = Dense(40)(dropout)\n",
    "output = Dense(units=6, activation='sigmoid',kernel_regularizer=regularizers.l2(0.01))(conc)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt)\n",
    "\n",
    "# Fitting Model to the data\n",
    "callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "hist_adam = model.fit(X_train, y_train, batch_size=1000, epochs=20, verbose=2, validation_data=(X_val, y_val),\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(X_test)\n",
    "X_test2 = pad_sequences(sequences_test,maxlen=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "\n",
    "# Predict on train, val and test datasets\n",
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test2)\n",
    "pred_val = model.predict(X_val)\n",
    "\n",
    "# Emply array to collect AUC scores\n",
    "AUC = np.zeros((3,6))\n",
    "AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "from sklearn import metrics\n",
    "for i,x in enumerate(col):\n",
    "    auc = np.array([metrics.roc_auc_score(y_train[:,i], pred_train[:,i]),\n",
    "                    metrics.roc_auc_score(y_val[:,i], pred_val[:,i]),\n",
    "                    metrics.roc_auc_score(y_test[x], pred_test[:,i])])\n",
    "    print(x,\"Train AUC:\",auc[0],\", Val AUC:\",auc[1],\", Test AUC:\",auc[2])\n",
    "    AUC[:,i] = auc\n",
    "    \n",
    "avg_auc = AUC.mean(axis=1)\n",
    "print(\"Average Train AUC:\",avg_auc[0],\", Average Val AUC:\",avg_auc[1],\", Average Test AUC:\",avg_auc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGDRqcCQD2is"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Amazon_ML_Glove_Embedding_with_CNN.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
